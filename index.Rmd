--- 
title: "mnist Dimensionality Reduction"
author: "James Franco"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---

# Introduction

The fundamental topic in unsupervised machine learning is that of revealing underlying structure in a dataset, without any information about the labels of the data points. This field has various practical uses, however the one we will mostly concern ourselves with in this report is its uses for exploratory data analysis and visualisation. When given data in a potentially very-high-dimensional format, we'd like to know a little bit about the structure of the data before applying any sort of machine learning methods. Often times, a small amount of domain knowledge can be extremely enlightening, and we can extract very useful hints about the sorts of analysis we may want to perform. This is interesting to me, because I personally feel that as off-the-shelf machine learning methods become more and more accessible, there is frequently an approach of "throw a bunch of models at the wall and see what sticks", which can be time consuming and ineffective. By using dimensionality reduction techniques, we can help speed up this method-finding process, and become more intentional with our decisions as data scientists and machine learning engineers.
